// Copyright 2022 Intel Corporation
// SPDX-FileCopyrightText: 2022 Intel Corporation
//
// SPDX-License-Identifier: Apache-2.0

/// @file
/// oneDNN Graph extension API

#ifndef DNNL_GRAPH_HPP
#define DNNL_GRAPH_HPP

#include "oneapi/dnnl/dnnl_common.hpp"
#include "oneapi/dnnl/dnnl_graph.h"

#include <limits>
#include <memory>
#include <string>
#include <utility>
#include <vector>

/// @addtogroup dnnl_api
/// @{

/// @addtogroup dnnl_graph_api Graph API
/// @{

namespace dnnl {
namespace graph {

/// @addtogroup dnnl_graph_api_status Status
/// Definitions of status values returned by the library functions.
///
/// @{

/// Status values returned by the library functions.
enum class status {
  /// The operation was successful
  success,
  /// The operation failed due to an out-of-memory condition
  out_of_memory,
  /// The operation failed because of incorrect function arguments
  invalid_arguments,
  /// The operation failed because requested functionality is not implemented
  unimplemented,
  /// The last available implementation is reached
  last_impl_reached,
  /// Primitive or engine failed on execution
  runtime_error,
  /// Queried element is not required for given primitive
  not_required,
  /// The graph is not legitimate
  invalid_graph,
  /// The operation is not legitimate according to op schema
  invalid_graph_op,
  /// The shape cannot be inferred or compiled
  invalid_shape,
  /// The data type cannot be inferred or compiled
  invalid_data_type,
};

/// @} dnnl_api_status

/// @addtogroup dnnl_graph_api_allocator Allocator
///
/// Definitions of allocator which is used to acquire memory resources in
/// partition compilation and execution.
///
/// @{

/// Allocator
struct allocator {
  /// Default constructor
  allocator();

  /// Constructs an allocator according to given function pointers
  ///
  /// @param host_malloc A pointer to malloc function for CPU
  /// @param host_free A pointer to free function for CPU
  allocator(dnnl_graph_host_allocate_f host_malloc,
            dnnl_graph_host_deallocate_f host_free);
};

/// @} dnnl_graph_api_allocator

/// @addtogroup dnnl_graph_api_engine Engine
/// @{

/// Creates an engine with a given allocator (compatible only with graph extension)
inline dnnl::engine make_engine_with_allocator(dnnl::engine::kind kind,
                                               size_t index,
                                               const allocator &alloc);

/// @} dnnl_graph_api_engine

/// @addtogroup dnnl_graph_api_logical_tensor Logical Tensor
///
/// Logical tensor describes the meta-data of the input or output tensor, like
/// elements data type, number of dimensions, size for each dimension (shape),
/// layout, and the property of the tensor.
///
/// Each logical tensor has an unique ID. The library uses logical tensor IDs to
/// build up the connections between operations if the output of one operation
/// has the same ID as the input of another operation. The meta-data in a
/// logical tensor may be enriched in the framework graph as it progresses
/// toward final execution. For example, the library doesn't require detailed
/// shape information at the operation and graph creation stage. But shape
/// information of input logical tensor will be required at partition
/// compilation stage. Logical tensor is not mutable. Users must create a new
/// logical tensor with the same ID to pass any new additional information to
/// oneDNN Graph API. Please note that the library also has unique IDs for
/// operations. The ID should be unique among different logical tensors, but it
/// can have the same value between a logical tensor and an operation.
///
/// @{

/// Logical tensor object
struct logical_tensor {
  using dims = std::vector<dim>;

  /// Data Type
  enum class data_type {
    undef,
    /// 16-bit/half-precision floating point.
    f16,
    /// non-standard 16-bit (bfloat16 w/ 7 bit mantissa) floating point.
    bf16,
    /// 32-bit/single-precision floating point.
    f32,
    /// 32-bit signed integer.
    s32,
    /// 8-bit signed integer.
    s8,
    /// 8-bit unsigned integer.
    u8,
  };

  /// Layout type
  enum class layout_type {
    /// Undefined layout type.
    undef,
    /// Any means to let the library to decide the layout for a tensor
    /// during partition compilation.
    any,
    /// Strided means that the layout of a tensor is determined by the
    /// strides field in the logical tensor.
    strided,
    /// Opaque means that the layout of a tensor is the library specific.
    /// Usually, an opaque layout is generated by a partition which is
    /// compiled with layout type any.
    opaque,
  };

  /// Tensor property
  enum class property_type {
    /// Undefined tensor property.
    undef,
    /// Variable means the tensor may be changed during computation or
    /// between different iterations.
    variable,
    /// Constant means the tensor will keep unchanged during computation and
    /// between different iterations. It's useful for the library to apply
    /// optimizations for constant tensors or cache constant tensors inside
    /// the library. For example, constant weight tensors in inference
    /// scenarios.
    constant,
  };

  /// Default constructor
  /// Construct an empty object
  logical_tensor() = default;

  /// Copy constructor
  logical_tensor(const logical_tensor &other) = default;

  /// Assignment operator
  logical_tensor &operator=(const logical_tensor &other) = default;

  /// Constructs a logical tensor object with ID, data type, ndims, layout
  /// type, and property type.
  ///
  /// @param tid Logical tensor ID.
  /// @param dtype Elements data type.
  /// @param ndims Number of dimensions. #DNNL_GRAPH_UNKNOWN_NDIMS for
  ///     an unknown number of dimensions, 0 for a scalar tensor.
  /// @param ltype Layout type.
  /// @param ptype Property type.
  logical_tensor(size_t tid, data_type dtype, int32_t ndims, layout_type ltype,
                 property_type ptype = property_type::undef);

  /// Delegated constructor.
  ///
  /// @param tid Logical tensor ID.
  /// @param dtype Elements data type.
  /// @param ltype Layout type.
  logical_tensor(size_t tid, data_type dtype,
                 layout_type ltype = layout_type::undef)
      : logical_tensor(tid, dtype, DNNL_GRAPH_UNKNOWN_NDIMS, ltype) {}

  /// Constructs a logical tensor object with basic information and detailed
  /// dims.
  ///
  /// @param tid Logical tensor ID.
  /// @param dtype Elements data type.
  /// @param adims Logical tensor dimensions. #DNNL_GRAPH_UNKNOWN_DIM for
  ///     dimensions of unknown size, 0 for zero-dimension tensor.
  /// @param ltype Layout type. If strided, the strides field in the
  ///     output logical tensor will be deduced accordingly.
  /// @param ptype Property type.
  logical_tensor(size_t tid, data_type dtype, const dims &adims,
                 layout_type ltype,
                 property_type ptype = property_type::undef);

  /// Constructs a logical tensor object with detailed dims and strides. The
  /// layout_type of the output logical tensor object will always be strided.
  ///
  /// @param tid Logical tensor ID.
  /// @param dtype Elements data type.
  /// @param adims Logical tensor dimensions. #DNNL_GRAPH_UNKNOWN_DIM for
  ///     dimensions of unknown size, 0 for zero-dimension tensor.
  /// @param strides Logical tensor strides.  #DNNL_GRAPH_UNKNOWN_DIM for unknown stride.
  ///     No negative stride is supported.
  /// @param ptype Property type.
  logical_tensor(size_t tid, data_type dtype, const dims &adims,
                 const dims &strides,
                 property_type ptype = property_type::undef);

  /// Constructs a logical tensor object with detailed dims and an opaque
  /// layout ID. layout_type of the output logical tensor object will always
  /// be opaque.
  ///
  /// @param tid Logical tensor ID.
  /// @param dtype Elements data type.
  /// @param adims Logical tensor dimensions. #DNNL_GRAPH_UNKNOWN_DIM for
  ///     dimensions of unknown size, 0 for zero-dimension tensor.
  /// @param lid Opaque layout id.
  /// @param ptype Property type
  logical_tensor(size_t tid, data_type dtype, const dims &adims, size_t lid,
                 property_type ptype = property_type::undef);

  /// Returns the dimensions of a logical tensor.
  ///
  /// @returns A vector describing the size of each dimension.
  dims get_dims() const;

  /// Returns the unique id of a logical tensor.
  ///
  /// @returns An integer value describing the ID.
  size_t get_id() const;

  /// Returns the data type of a logical tensor.
  ///
  /// @returns The data type.
  data_type get_data_type();

  /// Returns the property type of a logical tensor.
  ///
  /// @returns The property type.
  property_type get_property_type() const;

  /// Returns the layout type of a logical tensor.
  ///
  /// @returns The layout type.
  layout_type get_layout_type() const;

  /// Returns the layout ID of a logical tensor. The API should be called on a
  /// logical tensor with opaque layout type. Otherwise, an exception will be
  /// raised.
  ///
  /// @returns Layout ID.
  size_t get_layout_id() const;

  /// Returns the strides of a logical tensor. The API should be called on a
  /// logical tensor with strided layout type. Otherwise, an exception will be
  /// raised.
  ///
  /// @returns A vector describing the stride size of each dimension.
  dims get_strides() const;

  /// Returns memory size in bytes required by this logical tensor.
  ///
  /// @returns The memory size in bytes.
  size_t get_mem_size() const;

  /// Compares if two logical tenors are equal. Users can decide accordingly
  /// if layout reordering is needed for two logical tensors. The method will
  /// return true for below two circumstances:
  ///
  /// 1. the two logical tensors are equal regarding each field in the struct,
  /// eg. id, ndims, dims, layout type, property, etc.
  /// 2. If all other fields are equal but the layout types in two logical
  /// tensors are different, the method will return true when the underlying
  /// memory layout is the same. For example, one logical tensor has strided
  /// layout type while the other one has opaque layout type, but underneath,
  /// both layouts are NHWC, the method will still return true for this case.
  ///
  /// @param lt The input logical tensor to be compared.
  /// @returns @c true if the two logical tensors are equal. @c false otherwise
  bool is_equal(const logical_tensor &lt);
};

/// @} dnnl_graph_api_logical_tensor

/// @addtogroup dnnl_graph_api_tensor Tensor
///
/// Tensor is an abstraction for multi-dimensional input and output data needed
/// in the execution of a compiled partition. A tensor object encapsulates a
/// handle to a memory buffer allocated on a specific engine and a logical
/// tensor which describes the dimensions, elements data type, and memory
/// layout.
///
/// @{

/// A tensor object
struct tensor {

  /// Default constructor. Constructs an empty object.
  tensor() = default;

  /// Constructs a tensor object according to a given logical tensor, an
  /// engine, and a memory handle.
  ///
  /// @param lt The given logical tensor
  /// @param aengine Engine to store the data on.
  /// @param handle Handle of memory buffer to use as an underlying storage.
  tensor(const logical_tensor &lt, const engine &aengine, void *handle);

  /// Returns the underlying memory buffer.
  ///
  /// On the CPU engine, or when using USM, this is a pointer to the
  /// allocated memory.
  void *get_data_handle() const;

  /// Sets the underlying memory handle.
  ///
  /// @param handle Memory handle.
  void set_data_handle(void *handle);

  /// Returns the associated engine.
  ///
  /// @returns An engine object
  engine get_engine() const;
};

/// @} dnnl_graph_api_tensor

/// @addtogroup dnnl_graph_api_compiled_partition Compiled Partition
///
/// A compiled partition represents the generated kernels specialized for a
/// partition on a target hardware (engine) with input and output information
/// specified by the logical tensors.
///
/// @{

/// A compiled partition object.
struct compiled_partition{
  /// Default constructor. Constructs an empty object.
  compiled_partition() = default;

  /// Queries an input or output logical tensor according to tensor ID. If the
  /// tensor ID doesn't belong to any input or output of the compiled
  /// partition, an exception will be raised by the API.
  ///
  /// @param tid The unique id of required tensor.
  /// @returns The logical tensor.
  logical_tensor query_logical_tensor(size_t tid) const;

  /// Returns the hint of in-place pairs from a compiled partition. It
  /// indicates that an input and an output of the partition can share the
  /// same memory buffer for computation. In-place computation helps to reduce
  /// the memory footprint and improves cache locality. But since the library
  /// may not have a global view of user's application, it's possible that the
  /// input tensor is used at other places in user's computation graph. In
  /// this case, the user should take the in-place pair as a hint and pass a
  /// different memory buffer for output tensor to avoid overwriting the input
  /// memory buffer which will probably cause unexpected incorrect results.
  ///
  /// @returns A list of pairs of input and output IDs.
  std::vector<std::pair<size_t, size_t>> get_inplace_ports() const;

  /// Execute a compiled partition.
  ///
  /// @param astream Stream object to run over.
  /// @param inputs A list of input tensors.
  /// @param outputs A list of output tensors.
  void execute(dnnl::stream &astream, const std::vector<tensor> &inputs,
               const std::vector<tensor> &outputs) const;
};

/// @} dnnl_graph_api_compiled_partition

/// @addtogroup dnnl_graph_api_op Op
///
/// OP is an abstraction of computation logic for deep neural network
/// operations. An op object encapsulates an operation kind which describes the
/// computation logic, an unique ID which differentiates operations with the
/// same kind, and logical tensors which describes the input and output of the
/// operation and its connections to other operations in the graph.
///
/// @{

/// An op object.
struct op {
  /// Kinds of operations
  enum class kind {
    Abs ,
    AbsBackward ,
    Add ,
    AvgPool ,
    AvgPoolBackward ,
    BatchNormForwardTraining ,
    BatchNormInference ,
    BatchNormTrainingBackward ,
    BiasAdd ,
    BiasAddBackward ,
    Clamp ,
    ClampBackward ,
    Concat ,
    Convolution ,
    ConvolutionBackwardData ,
    ConvolutionBackwardWeights ,
    ConvTranspose ,
    ConvTransposeBackwardData ,
    ConvTransposeBackwardWeights ,
    Dequantize ,
    Divide ,
    DynamicDequantize ,
    DynamicQuantize ,
    Elu ,
    EluBackward ,
    End ,
    Exp ,
    GELU ,
    GELUBackward ,
    HardSwish ,
    HardSwishBackward ,
    Interpolate ,
    InterpolateBackward ,
    LayerNorm ,
    LayerNormBackward ,
    LeakyReLU ,
    Log ,
    LogSoftmax ,
    LogSoftmaxBackward ,
    MatMul ,
    Maximum ,
    MaxPool ,
    MaxPoolBackward ,
    Minimum ,
    Mish ,
    MishBackward ,
    Multiply ,
    PReLU ,
    PReLUBackward ,
    Quantize ,
    Reciprocal ,
    ReduceL1 ,
    ReduceL2 ,
    ReduceMax ,
    ReduceMean ,
    ReduceMin ,
    ReduceProd ,
    ReduceSum ,
    ReLU ,
    ReLUBackward ,
    Reorder ,
    Round ,
    Sigmoid ,
    SigmoidBackward ,
    SoftMax ,
    SoftMaxBackward ,
    SoftPlus ,
    SoftPlusBackward ,
    Sqrt ,
    SqrtBackward ,
    Square ,
    SquaredDifference ,
    StaticReshape ,
    StaticTranspose ,
    Subtract ,
    Tanh ,
    TanhBackward ,
    TypeCast ,
    Wildcard ,
    // Sentinel
    LastSymbol ,
  };

  /// Attributes of operations. Different operations support different
  /// attributes. Check the document of each operation for what attributes are
  /// supported and what are the potential values for them. Missing required
  /// attribute or illegal attribute value may lead to failure when adding the
  /// operation to a graph.
  enum class attr {
    /// Undefined op attribute.
    undef ,

    // float32 attributes. The value of these attributes can be any single
    // float32 number.

    /// Specifies an alpha attribute to an op.
    alpha ,
    /// Specifies an beta attribute to an op.
    beta ,
    /// Specifies an epsilon attribute to an op.
    epsilon ,
    /// Specifies a max attribute to an op.
    max ,
    /// Specifies a min attribute to an op.
    min ,
    /// Specifies a momentum attribute to an op.
    momentum ,

    // float32 vector attributes. The value of these attributes can be a
    // vector of float32 numbers.

    /// Specifies a scales attribute to an op.
    scales ,

    // int64_t attributes. The value of these attributes can be any single
    // int64 number.

    /// Specifies an axis attribute to an op.
    axis ,
    /// Specifies a begin_norm_axis attribute to an op.
    begin_norm_axis ,
    /// Specifies a groups attribute to an op.
    groups ,

    // int64_t vector attributes. The value of these attributes can be a
    // vector of int64 numbers.

    /// Specifies an axes attribute to an op.
    axes ,
    /// Specifies a dilations attribute to an op.
    dilations ,
    /// Specifies an dst_shape attribute to an op.
    dst_shape ,
    /// Specifies a kernel attribute to an op.
    kernel ,
    /// Specifies an order attribute to an op.
    order ,
    /// Specifies an output_padding attribute to an op.
    output_padding ,
    /// Specifies a pads_begin attribute to an op.
    pads_begin ,
    /// Specifies a pads_end attribute to an op.
    pads_end ,
    /// Specifies a shape attribute to an op.
    shape ,
    /// Specifies a sizes attribute to an op.
    sizes ,
    /// Specifies an src_shape attribute to an op.
    src_shape ,
    /// Specifies a strides attribute to an op.
    strides ,
    /// Specifies a weight_shape attribute to an op.
    weights_shape ,
    /// Specifies a zps attribute to an op.
    zps ,

    // bool attributes. The value of these attributes can be any single bool
    // value.

    /// Specifies an exclude_pad attribute to an op.
    exclude_pad ,
    /// Specifies a keep_dims attribute to an op.
    keep_dims ,
    /// Specifies a keep_stats attribute to an op.
    keep_stats ,
    /// Specifies a per_channel_broadcast attribute to an op.
    per_channel_broadcast ,
    /// Specifies a special_zero attribute to an op.
    special_zero ,
    /// Specifies a transpose_a attribute to an op.
    transpose_a ,
    /// Specifies a transpose_b attribute to an op.
    transpose_b ,
    /// Specifies an use_affine attribute to an op.
    use_affine ,
    /// Specifies an use_dst attribute to an op.
    use_dst ,

    // string attributes. The value of these attributes can be a string.

    /// Specifies an auto_broadcast attribute to an op. The value can be
    /// "none" or "numpy".
    auto_broadcast ,
    /// Specifies an auto_pad attribute to an op. The value can be "none",
    /// "same_upper", "same_lower", or "valid".
    auto_pad ,
    /// Specifies an coordinate_transformation_mode attribute to an op. The
    /// value can be "half_pixel" or "align_corners". The attribute is
    /// defined for Interpolate operations.
    coordinate_transformation_mode ,
    /// Specifies a data_format of an op. The value can be "NCX" or "NXC".
    data_format ,
    /// Specifies a mode attribute of an op. The value can be "nearest",
    /// "linear", "bilinear", or "trilinear". The attribute is defined for
    /// Interpolate operations.
    mode ,
    /// Specifies a qtype attribute to an op. The value can be "per_channel"
    /// or "per_tensor". The attribute is defined for quantization
    /// operations.
    qtype ,
    /// Specifies a rounding_type attribute to an op. The value can be
    /// "ceil" or "floor".
    rounding_type ,
    /// Specifies a weights_format of an op. The value can be "OIX", "XIO",
    /// "IOX", or "XOI". Different operations may support different values.
    weights_format ,
  };

  /// Constructs an op object with an unique ID, an operation kind, and a name
  /// string.
  ///
  /// @param id The unique ID of the op.
  /// @param akind The op kind specifies which computation is represented by
  ///     the op, such as Convolution or ReLU.
  /// @param name The string added as the op name.
  op(size_t id, kind akind, const std::string &name = "");

  /// Constructs an op object with an unique ID, an operation kind, and
  /// input/output logical tensors.
  ///
  /// @param id The unique ID of this op.
  /// @param akind The op kind specifies which computation is represented by
  ///     this op, such as Convolution or ReLU.
  /// @param inputs Input logical tensor to be bound to this op.
  /// @param outputs Output logical tensor to be bound to this op.
  /// @param name The string added as the op name.
  op(size_t id, kind akind, const std::vector<logical_tensor> &inputs,
     const std::vector<logical_tensor> &outputs,
     const std::string &name = "");

  /// Adds an input logical tensor to the op.
  ///
  /// @param t Input logical tensor.
  void add_input(const logical_tensor &t);

  /// Adds a vector of input logical tensors to the op.
  ///
  /// @param ts The list of input logical tensors.
  void add_inputs(const std::vector<logical_tensor> &ts);

  /// Adds an output logical tensor to the op.
  ///
  /// @param t Output logical tensor.
  void add_output(const logical_tensor &t);

  /// Adds a vector of output logical tensors to the op.
  ///
  /// @param ts The list of output logical tensors.
  void add_outputs(const std::vector<logical_tensor> &ts);

  /// Sets the attribute according to the name and type.
  ///
  /// @tparam Type Attribute's type.
  /// @param name Attribute's name.
  /// @param value The attribute's value.
  /// @returns The Op self. Raises an exception if Type is incompatible with name.
  template <typename Type>
  op &set_attr(attr name, const Type &value);
};

/// @} dnnl_graph_api_op

/// @addtogroup dnnl_graph_api_partition Partition
///
/// Partition represents a collection of operations and their input and output
/// logical tensors identified by library as the basic unit for compilation and
/// execution.
///
/// @{

/// A partition object.
struct partition{
  /// Policy specifications for partitioning.
  enum class policy {
    /// Fusion policy returns partitions with typical post-op fusions, eg.
    /// Convolution + ReLU or other element-wise operations or a chian of
    /// post-ops.
    fusion,
    /// Debug policy doesn't not apply any fusions. It returns partitions
    /// with single operations in each partition. The policy is useful when
    /// users notice any bug or correctness issue in fusion policy.
    debug,
  };

  partition() = default;

  /// Creates a new partition with a given operator and engine kind. The API
  /// is used to create a partition from an operation directly without
  /// creating the graph and calling `get_partitions()`. The output partition
  /// contains only one operation.
  ///
  /// @param aop An operation used to create the partition.
  /// @param ekind Engine kind.
  partition(const op &aop, engine::kind ekind);

  /// Returns the number of operations contained in the partition.
  ///
  /// @returns Number of operations.
  size_t get_ops_num() const;

  /// Returns all operation IDs contained in the partition.
  ///
  /// @returns An unordered set of operation IDs.
  std::vector<size_t> get_ops() const;

  /// Returns the unique ID of the partition. Partition ID is generated by the
  /// library internally. The ID can be used for debugging purpose or verbose.
  ///
  /// @returns ID of the partition.
  size_t get_id() const;

  /// Compiles a partition with given input and output logical tensors. The
  /// output logical tensors can contain unknown dimensions. For this case,
  /// the compilation will deduce the output shapes according to input shapes.
  /// The output logical tensors can also have layout type `any`. The
  /// compilation will choose the optimal layout for output tensors. The
  /// optimal layout will be represented as an opaque layout ID saved in the
  /// output logical tensor.
  ///
  /// @param inputs A list of input logical tensors.
  /// @param outputs A list of output logical tensors.
  /// @param e The engine used to compile the partition.
  /// @returns A compiled partition.
  compiled_partition compile(const std::vector<logical_tensor> &inputs,
                             const std::vector<logical_tensor> &outputs,
                             const engine &e) const;
  /// Returns the supporting status of a partition. Some operations may not be
  /// supported by the library under certain circumstances. During
  /// partitioning stage, unsupported partitions will be returned to users
  /// with each containing an unsupported operation. Users should check the
  /// supporting status of a partition before transforming the computation
  /// graph or compiling the partition.
  ///
  /// @returns @c true if this partition is supported or @c false if this
  ///     partition isn't supported by the library
  bool is_supported() const;

  /// Returns a list of input logical tensors from the partition.
  ///
  /// @returns A list of input logical tensors.
  std::vector<logical_tensor> get_input_ports() const;

  /// Returns a list of output logical tensors from the partition.
  ///
  /// @returns A list of output logical tensor.
  std::vector<logical_tensor> get_output_ports() const;

  /// Returns the engine kind of the partition
  ///
  /// @returns The engine kind
  engine::kind get_engine_kind() const;
};

/// @} dnnl_graph_api_partition

/// @addtogroup dnnl_graph_api_graph Graph
///
/// Graph represents a computational DAG with a set of operations.
/// #dnnl::graph::graph::add_op() adds an operation and its input and output
/// logical tensors into a graph. The library accumulates the operations and
/// logical tensors and constructs and validates the graph as an internal state.
/// A graph object is associated to a specific engine kind. The partitions
/// returned from the graph will inherit the engine kind of the graph.
///
/// @{

/// A graph object.
struct graph {
  /// Constructs a graph with an engine kind.
  ///
  /// @param engine_kind Engine kind.
  graph(dnnl::engine::kind engine_kind);

  /// Creates a new empty graph with an engine kind and a floating-point math
  /// mode. All partitions returned from the graph will inherit the engine
  /// kind and floating-point math mode.
  ///
  /// @param engine_kind Engine kind.
  /// @param mode Floating-point math mode.
  graph(dnnl::engine::kind engine_kind, dnnl::fpmath_mode mode);

  /// Adds an op into the graph to construct a computational DAG. The API will
  /// return failure if the operator has already been added to the graph or
  /// the operation cannot pass the schema check in the library (eg. input and
  /// output numbers and data types, the attributes of the operation, etc.).
  ///
  /// @param op An operation to be added.
  /// @param allow_exception A flag indicating whether the method is allowed
  ///     to throw an exception if it fails to add the op to the graph.
  /// @returns #status::success or a status describing the error otherwise.
  status add_op(const op &op, bool allow_exception = true);

  /// Finalizes a graph. It means users have finished adding operations into
  /// the graph and the graph is ready for partitioning. Adding a new
  /// operation into a finalized graph will return failures. Similarly,
  /// partitioning on a un-finalized graph will also return failures.
  void finalize();

  /// Checks if a graph is finalized.
  ///
  /// @return True if the graph is finalized or false if the graph is not
  /// finalized.
  bool is_finalized() const;

  /// Gets filtered partitions from a graph. Partitions will be claimed
  /// internally according to the capability of the library, the engine kind
  /// of the graph, and the policy.
  ///
  /// @param policy Partition policy, defaults to policy
  ///     #dnnl::graph::partition::policy::fusion.
  /// @return A vector storing the partitions.
  std::vector<partition>
  get_partitions(partition::policy policy = partition::policy::fusion);
};

/// @} dnnl_graph_api_graph

} // namespace graph
} // namespace dnnl


/// @} dnnl_graph_api

/// @} dnnl_api

#endif
